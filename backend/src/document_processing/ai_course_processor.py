"""
AI-Powered Course Content Processor
S·ª≠ d·ª•ng AI ƒë·ªÉ ph√¢n t√≠ch v√† tr√≠ch xu·∫•t n·ªôi dung kh√≥a h·ªçc t·ª´ PDF
"""

import logging
from typing import Dict, List, Optional, Tuple
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from ..llm_models import llm_manager

logger = logging.getLogger(__name__)

class AICourseProcessor:
    """X·ª≠ l√Ω n·ªôi dung kh√≥a h·ªçc b·∫±ng AI thay v√¨ rules c·ª©ng"""
    
    def __init__(self):
        self.llm = llm_manager.get_llm()
        
        # Template ƒë·ªÉ ph√¢n t√≠ch v√† d·ªãch n·ªôi dung PDF
        self.analysis_prompt = PromptTemplate(
            input_variables=["content"],
            template="""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√†i li·ªáu kh√≥a h·ªçc. Nhi·ªám v·ª• c·ªßa b·∫°n:

1. **Ph√°t hi·ªán ng√¥n ng·ªØ**: X√°c ƒë·ªãnh n·ªôi dung ti·∫øng Anh hay ti·∫øng Vi·ªát
2. **D·ªãch thu·∫≠t**: N·∫øu l√† ti·∫øng Anh, d·ªãch to√†n b·ªô sang ti·∫øng Vi·ªát t·ª± nhi√™n
3. **Ph√¢n t√≠ch c·∫•u tr√∫c**: Tr√≠ch xu·∫•t 3 ph·∫ßn ch√≠nh c·ªßa kh√≥a h·ªçc

**N·ªôi dung c·∫ßn ph√¢n t√≠ch:**
{content}

**Y√™u c·∫ßu output JSON:**
```json
{{
    "language_detected": "en" ho·∫∑c "vi",
    "course_sections": {{
        "overview": "T√™n kh√≥a h·ªçc, m√¥ t·∫£ t·ªïng quan, th·ªùi l∆∞·ª£ng h·ªçc",
        "objectives_audience": "M·ª•c ti√™u kh√≥a h·ªçc, ƒë·ªëi t∆∞·ª£ng tham gia, y√™u c·∫ßu ti√™n quy·∫øt", 
        "detailed_content": "N·ªôi dung chi ti·∫øt, ch∆∞∆°ng tr√¨nh h·ªçc, module"
    }},
    "translated_content": "To√†n b·ªô n·ªôi dung ƒë√£ d·ªãch ti·∫øng Vi·ªát (n·∫øu c·∫ßn)"
}}
```

**L∆∞u √Ω quan tr·ªçng:**
- N·∫øu ph√°t hi·ªán ti·∫øng Anh: d·ªãch sang ti·∫øng Vi·ªát t·ª± nhi√™n, gi·ªØ nguy√™n thu·∫≠t ng·ªØ k·ªπ thu·∫≠t
- Ph√¢n chia n·ªôi dung th√†nh 3 ph·∫ßn r√µ r√†ng theo y√™u c·∫ßu
- B·ªè qua ph·∫ßn "h√¨nh th·ª©c ƒë√†o t·∫°o" - kh√¥ng ƒë∆∞a v√†o content
- Gi·ªØ nguy√™n c·∫•u tr√∫c, ƒë·ªãnh d·∫°ng quan tr·ªçng
"""
        )
        
        # Template ƒë·ªÉ matching profile kh√°ch h√†ng
        self.matching_prompt = PromptTemplate(
            input_variables=["course_info", "user_profile"],
            template="""
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n kh√≥a h·ªçc IT. H√£y ph√¢n t√≠ch m·ª©c ƒë·ªô ph√π h·ª£p gi·ªØa kh√≥a h·ªçc v√† profile kh√°ch h√†ng.

**Th√¥ng tin kh√≥a h·ªçc:**
{course_info}

**Profile kh√°ch h√†ng:**
{user_profile}

**Ph√¢n t√≠ch confidence matching:**
```json
{{
    "confidence_score": 0.85,
    "matching_analysis": {{
        "strengths": ["ƒêi·ªÉm m·∫°nh ph√π h·ª£p v·ªõi kh√≥a h·ªçc"],
        "gaps": ["K·ªπ nƒÉng c·∫ßn b·ªï sung tr∆∞·ªõc khi h·ªçc"],
        "recommendations": ["G·ª£i √Ω c·ª• th·ªÉ cho kh√°ch h√†ng"]
    }},
    "suitability_level": "high/medium/low"
}}
```
"""
        )
        
        # Template cho t∆∞ v·∫•n m√¥ng lung
        self.consultation_prompt = PromptTemplate(
            input_variables=["field", "available_courses"],
            template="""
Kh√°ch h√†ng ƒëang quan t√¢m ƒë·∫øn lƒ©nh v·ª±c: {field}

**Kh√≥a h·ªçc c√≥ s·∫µn trong lƒ©nh v·ª±c:**
{available_courses}

**T·∫°o response t∆∞ v·∫•n theo format:**

üéØ **Kh√≥a h·ªçc trong lƒ©nh v·ª±c {field}:**
[Li·ªát k√™ 3-5 kh√≥a ph√π h·ª£p nh·∫•t v·ªõi m√¥ t·∫£ ng·∫Øn g·ªçn]

üìã **ƒê·ªÉ t∆∞ v·∫•n ch√≠nh x√°c h∆°n, b·∫°n c√≥ th·ªÉ chia s·∫ª:**
1. **Lƒ©nh v·ª±c h·ªçc t·∫≠p/l√†m vi·ªác hi·ªán t·∫°i:** [?]
2. **K·ªπ nƒÉng & kinh nghi·ªám c√≥ s·∫µn:** [?] 
3. **Mong ƒë·ª£i sau kh√≥a h·ªçc:** [?]

üí° *D·ª±a v√†o th√¥ng tin n√†y, t√¥i s·∫Ω g·ª£i √Ω kh√≥a h·ªçc ph√π h·ª£p nh·∫•t v·ªõi m·ª•c ti√™u c·ªßa b·∫°n!*
"""
        )

    async def process_pdf_content(self, raw_content: str) -> Dict:
        """
        X·ª≠ l√Ω n·ªôi dung PDF b·∫±ng AI
        
        Args:
            raw_content: N·ªôi dung th√¥ t·ª´ PDF
            
        Returns:
            Dict ch·ª©a n·ªôi dung ƒë√£ x·ª≠ l√Ω theo c·∫•u tr√∫c m·ªõi
        """
        try:
            # G·ªçi AI ƒë·ªÉ ph√¢n t√≠ch v√† x·ª≠ l√Ω
            prompt_text = self.analysis_prompt.format(content=raw_content)
            response = await self.llm.ainvoke([HumanMessage(content=prompt_text)])
            
            # Parse JSON response
            result = self._parse_ai_response(response.content)
            
            logger.info(f"‚úÖ AI processed PDF: language={result.get('language_detected')}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå AI processing failed: {e}")
            # Fallback to basic processing
            return self._fallback_processing(raw_content)
    
    def _parse_ai_response(self, response_text: str) -> Dict:
        """Parse JSON response t·ª´ AI"""
        try:
            import json
            # T√¨m JSON block trong response
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != -1:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
            else:
                raise ValueError("No JSON found in response")
                
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"Failed to parse AI response: {e}")
            # Return basic structure if parsing fails
            return {
                "language_detected": "vi",
                "course_sections": {
                    "overview": response_text[:500],
                    "objectives_audience": response_text[500:1000], 
                    "detailed_content": response_text[1000:]
                }
            }
    
    def _fallback_processing(self, content: str) -> Dict:
        """Fallback processing n·∫øu AI fail"""
        # Split content th√†nh 3 ph·∫ßn ƒë·ªÅu nhau
        content_length = len(content)
        third = content_length // 3
        
        return {
            "language_detected": "vi",
            "course_sections": {
                "overview": content[:third],
                "objectives_audience": content[third:2*third],
                "detailed_content": content[2*third:]
            }
        }
    
    async def calculate_matching_confidence(self, course_info: str, user_profile: str) -> Dict:
        """
        T√≠nh confidence score gi·ªØa kh√≥a h·ªçc v√† profile user
        
        Args:
            course_info: Th√¥ng tin kh√≥a h·ªçc (objectives_audience section)
            user_profile: Profile kh√°ch h√†ng
            
        Returns:
            Dict ch·ª©a confidence score v√† ph√¢n t√≠ch
        """
        try:
            prompt_text = self.matching_prompt.format(
                course_info=course_info,
                user_profile=user_profile
            )
            
            response = await self.llm.ainvoke([HumanMessage(content=prompt_text)])
            return self._parse_ai_response(response.content)
            
        except Exception as e:
            logger.error(f"‚ùå Confidence calculation failed: {e}")
            # Default medium confidence
            return {
                "confidence_score": 0.5,
                "matching_analysis": {
                    "strengths": ["C·∫ßn ph√¢n t√≠ch th√™m"],
                    "gaps": ["Ch∆∞a x√°c ƒë·ªãnh ƒë∆∞·ª£c"],
                    "recommendations": ["Vui l√≤ng cung c·∫•p th√™m th√¥ng tin"]
                },
                "suitability_level": "medium"
            }
    
    async def generate_field_consultation(self, field: str, available_courses: List[str]) -> str:
        """
        T·∫°o response t∆∞ v·∫•n cho kh√°ch h√†ng m√¥ng lung
        
        Args:
            field: Lƒ©nh v·ª±c quan t√¢m (v√≠ d·ª•: "Cloud Computing")
            available_courses: List kh√≥a h·ªçc c√≥ s·∫µn
            
        Returns:
            String response cho kh√°ch h√†ng
        """
        try:
            courses_text = "\n".join([f"- {course}" for course in available_courses])
            
            prompt_text = self.consultation_prompt.format(
                field=field,
                available_courses=courses_text
            )
            
            response = await self.llm.ainvoke([HumanMessage(content=prompt_text)])
            return response.content
            
        except Exception as e:
            logger.error(f"‚ùå Consultation generation failed: {e}")
            return f"Hi·ªán t·∫°i ch√∫ng t√¥i c√≥ c√°c kh√≥a h·ªçc v·ªÅ {field}. B·∫°n c√≥ th·ªÉ chia s·∫ª th√™m v·ªÅ background ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c h∆°n?"

# Global instance
ai_course_processor = AICourseProcessor()